{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from packaging import version\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"classification\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier\n",
    "class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)[source]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "baseline_accuracy = knn_clf.score(X_test, y_test)\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5, 6]}]\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train[:10_000], y_train[:10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.fit(X_train, y_train)\n",
    "tuned_accuracy = grid_search.score(X_test, y_test)\n",
    "tuned_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3)  # add shuffle=True if the dataset is not\n",
    "                                       # already shuffled\n",
    "for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "    clone_clf = clone(knn_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_perfect_predictions = y_train  # pretend we reached perfection\n",
    "confusion_matrix(y_train, y_train_perfect_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train, y_train_pred,average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cell also computes the precision: TP / (FP + TP)\n",
    "cm[1, 1] / (cm[0, 1] + cm[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_train_pred,average=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, y_train_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cell also computes the f1 score\n",
    "cm[1, 1] / (cm[1, 1] + (cm[1, 0] + cm[0, 1]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(knn_clf, X_train, y_train, cv=3,method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(\"float64\"))\n",
    "cross_val_score(knn_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train_scaled, y_train, cv=3)\n",
    "plt.rc('font', size=9)  # extra code – make the text smaller\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=10)  # extra code\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = (y_train_pred != y_train)\n",
    "plt.rc('font', size=10)  # extra code\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n",
    "                                        sample_weight=sample_weight,\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cell generates and saves Figure 3–9\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "plt.rc('font', size=9)\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[0])\n",
    "axs[0].set_title(\"Confusion matrix\")\n",
    "plt.rc('font', size=10)\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[1],\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "axs[1].set_title(\"CM normalized by row\")\n",
    "save_fig(\"confusion_matrix_plot_1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – this cell generates and saves Figure 3–10\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "plt.rc('font', size=10)\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[0],\n",
    "                                        sample_weight=sample_weight,\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "axs[0].set_title(\"Errors normalized by row\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, ax=axs[1],\n",
    "                                        sample_weight=sample_weight,\n",
    "                                        normalize=\"pred\", values_format=\".0%\")\n",
    "axs[1].set_title(\"Errors normalized by column\")\n",
    "save_fig(\"confusion_matrix_plot_2\")\n",
    "plt.show()\n",
    "plt.rc('font', size=14)  # make fonts great again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))  # extra code – it's not needed, just formatting\n",
    "plt.plot(thresholds[5], precision[5][:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds[5], recall[5][:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.vlines(thresholds[5], 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n",
    "\n",
    "# extra code – this section just beautifies and saves Figure 3–5\n",
    "idx = (thresholds[5] >= thresholds[5]).argmax()  # first index ≥ threshold\n",
    "plt.plot(thresholds[5][idx], precision[5][idx], \"bo\")\n",
    "plt.plot(thresholds[5][idx], recall[5][idx], \"go\")\n",
    "plt.axis([-50000, 50000, 0, 1])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"center right\")\n",
    "save_fig(\"precision_recall_vs_threshold_plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Step 4: Wrap KNN in OneVsRestClassifier for multiclass handling\n",
    "ovr = OneVsRestClassifier(KNeighborsClassifier(n_neighbors= 4, weights= 'distance'))\n",
    "ovr.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict probabilities for each class\n",
    "y_scores = ovr.predict_proba(X_test)\n",
    "\n",
    "# Step 6: Compute Precision-Recall for each class\n",
    "for i in range(len(ovr.classes_)):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test == i, y_scores[:, i])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, precision[:-1], label=f\"Precision (Class {i})\", color='b', linewidth=2)\n",
    "    plt.plot(thresholds, recall[:-1], label=f\"Recall (Class {i})\", color='g', linewidth=2)\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Precision / Recall\")\n",
    "    plt.title(f\"Precision-Recall vs Threshold for Class {i}\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the test labels\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Plot Precision vs. Recall vs. Threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\", color='b', linewidth=2)\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\", color='g', linewidth=2)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision / Recall\")\n",
    "plt.title(\"Precision-Recall vs Threshold\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
